{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Y_RuaKeqFZg_"
   },
   "outputs": [],
   "source": [
    "my_review = \"Today was a cold day. I went running in the morning beside the river and saw many dogs running aroung the playground. May Covid leave the world soon. Visited Grandparents as well.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c0VegGW4F4la",
    "outputId": "496b4fed-3e12-428e-b11b-06633bfb0042"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', 'o', 'd', 'a', 'y', ' ', 'w', 'a', 's', ' ', 'a', ' ', 'c', 'o', 'l', 'd', ' ', 'd', 'a', 'y', '.', ' ', 'I', ' ', 'w', 'e', 'n', 't', ' ', 'r', 'u', 'n', 'n', 'i', 'n', 'g', ' ', 'i', 'n', ' ', 't', 'h', 'e', ' ', 'm', 'o', 'r', 'n', 'i', 'n', 'g', ' ', 'b', 'e', 's', 'i', 'd', 'e', ' ', 't', 'h', 'e', ' ', 'r', 'i', 'v', 'e', 'r', ' ', 'a', 'n', 'd', ' ', 's', 'a', 'w', ' ', 'm', 'a', 'n', 'y', ' ', 'd', 'o', 'g', 's', ' ', 'r', 'u', 'n', 'n', 'i', 'n', 'g', ' ', 'a', 'r', 'o', 'u', 'n', 'g', ' ', 't', 'h', 'e', ' ', 'p', 'l', 'a', 'y', 'g', 'r', 'o', 'u', 'n', 'd', '.', ' ', 'M', 'a', 'y', ' ', 'C', 'o', 'v', 'i', 'd', ' ', 'l', 'e', 'a', 'v', 'e', ' ', 't', 'h', 'e', ' ', 'w', 'o', 'r', 'l', 'd', ' ', 's', 'o', 'o', 'n', '.', ' ', 'V', 'i', 's', 'i', 't', 'e', 'd', ' ', 'G', 'r', 'a', 'n', 'd', 'p', 'a', 'r', 'e', 'n', 't', 's', ' ', 'a', 's', ' ', 'w', 'e', 'l', 'l', '.']\n"
     ]
    }
   ],
   "source": [
    "#Text into Tokens\n",
    "print(list(my_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TPC_WbexGA9p",
    "outputId": "27810ead-669e-44bf-a9df-527d08b6166c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Today', 'was', 'a', 'cold', 'day.', 'I', 'went', 'running', 'in', 'the', 'morning', 'beside', 'the', 'river', 'and', 'saw', 'many', 'dogs', 'running', 'aroung', 'the', 'playground.', 'May', 'Covid', 'leave', 'the', 'world', 'soon.', 'Visited', 'Grandparents', 'as', 'well.']\n"
     ]
    }
   ],
   "source": [
    "#Text into Words\n",
    "print(my_review.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "BwksOF0mGF0H"
   },
   "outputs": [],
   "source": [
    "#n gram representation\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S2BifjlkGNRP",
    "outputId": "c5393e02-7ceb-4909-b26d-1cbccbd405c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Today', 'was'), ('was', 'a'), ('a', 'cold'), ('cold', 'day.'), ('day.', 'I'), ('I', 'went'), ('went', 'running'), ('running', 'in'), ('in', 'the'), ('the', 'morning'), ('morning', 'beside'), ('beside', 'the'), ('the', 'river'), ('river', 'and'), ('and', 'saw'), ('saw', 'many'), ('many', 'dogs'), ('dogs', 'running'), ('running', 'aroung'), ('aroung', 'the'), ('the', 'playground.'), ('playground.', 'May'), ('May', 'Covid'), ('Covid', 'leave'), ('leave', 'the'), ('the', 'world'), ('world', 'soon.'), ('soon.', 'Visited'), ('Visited', 'Grandparents'), ('Grandparents', 'as'), ('as', 'well.')]\n"
     ]
    }
   ],
   "source": [
    "print(list(ngrams(my_review.split(),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3xQDdDy2GRtm",
    "outputId": "002e6c84-103e-4639-d63a-1a48c8387804"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Today', 'was', 'a'), ('was', 'a', 'cold'), ('a', 'cold', 'day.'), ('cold', 'day.', 'I'), ('day.', 'I', 'went'), ('I', 'went', 'running'), ('went', 'running', 'in'), ('running', 'in', 'the'), ('in', 'the', 'morning'), ('the', 'morning', 'beside'), ('morning', 'beside', 'the'), ('beside', 'the', 'river'), ('the', 'river', 'and'), ('river', 'and', 'saw'), ('and', 'saw', 'many'), ('saw', 'many', 'dogs'), ('many', 'dogs', 'running'), ('dogs', 'running', 'aroung'), ('running', 'aroung', 'the'), ('aroung', 'the', 'playground.'), ('the', 'playground.', 'May'), ('playground.', 'May', 'Covid'), ('May', 'Covid', 'leave'), ('Covid', 'leave', 'the'), ('leave', 'the', 'world'), ('the', 'world', 'soon.'), ('world', 'soon.', 'Visited'), ('soon.', 'Visited', 'Grandparents'), ('Visited', 'Grandparents', 'as'), ('Grandparents', 'as', 'well.')]\n"
     ]
    }
   ],
   "source": [
    "#ngram accepts a squence of words as its first argument and the number of words to be grouped as the\n",
    "#second argument.\n",
    "\n",
    "#Try 3 now\n",
    "print(list(ngrams(my_review.split(),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdcKlCGVKdfI"
   },
   "source": [
    "Supervised Machine Learning Models for example Naive Bayes use n-grams to improve feature space.\n",
    "n-grams are also used for spelling correction and text-summarization.\n",
    "\n",
    "However, a challenge is that it loses sequential nature of the text.\n",
    "Hence, used with shallow machine learning models.\n",
    "Rarely used in deep learning as architectures like RNN, Conv1D learn representation directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Zgk1AXSWGkfZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#One Hot Encoding\n",
    "class Dictionary(object):\n",
    "  def __init__(self):\n",
    "    self.word2idx = {}\n",
    "    self.idx2word = []\n",
    "    self.length = 0\n",
    "\n",
    "  def add_word(self,word):\n",
    "    if word not in self.idx2word:\n",
    "      self.idx2word.append(word)\n",
    "      self.word2idx[word] = self.length + 1\n",
    "      self.length += 1\n",
    "    return self.word2idx[word]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.idx2word)\n",
    "\n",
    "  def onehot_encoded(self,word):\n",
    "    vec = np.zeros(self.length)\n",
    "    vec[self.word2idx[word]] = 1\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tUdeoRaGIJ8f",
    "outputId": "75240672-2a25-44e3-8b2c-adad046335e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Today': 1, 'was': 2, 'a': 3, 'cold': 4, 'day.': 5, 'I': 6, 'went': 7, 'running': 8, 'in': 9, 'the': 10, 'morning': 11, 'beside': 12, 'river': 13, 'and': 14, 'saw': 15, 'many': 16, 'dogs': 17, 'aroung': 18, 'playground.': 19, 'May': 20, 'Covid': 21, 'leave': 22, 'world': 23, 'soon.': 24, 'Visited': 25, 'Grandparents': 26, 'as': 27, 'well.': 28}\n"
     ]
    }
   ],
   "source": [
    "dic = Dictionary()\n",
    "for tok in my_review.split():\n",
    "  dic.add_word(tok)\n",
    "print(dic.word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZtEErwCaJaz6",
    "outputId": "05b26d15-6e0f-4b6e-ca08-1e75d334e9a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic.onehot_encoded('cold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyKR2nuaKqEe"
   },
   "source": [
    "Challenges is that the data becomes too sparse hence size of vector will grow very quickly as unique\n",
    "word increase. --> Limitation. Hence rarely used in Deep Learning"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Chap6.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
