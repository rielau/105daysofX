{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Layers : Fundamental blocks of Neural Network\n",
    "import torch\n",
    "from torch.nn import Linear, ReLU\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5110, -0.6567, -0.7577, -0.6810, -0.7615]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myLayer = Linear(in_features=10, out_features=5, bias=True)\n",
    "inp = Variable(torch.randn(1,10))\n",
    "myLayer = Linear(in_features=10, out_features=5, bias=True)\n",
    "myLayer(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2691, -0.1108,  0.0096, -0.1537,  0.0539, -0.3024, -0.2335, -0.2521,\n",
       "          0.1516,  0.1294],\n",
       "        [-0.0597, -0.1476,  0.2644, -0.0724, -0.2074, -0.2400,  0.0589, -0.2135,\n",
       "          0.2398,  0.0371],\n",
       "        [-0.1165,  0.2973,  0.1117,  0.2851, -0.0919, -0.2946, -0.0039,  0.0359,\n",
       "          0.0583,  0.3125],\n",
       "        [ 0.2225,  0.2925, -0.2816,  0.0136,  0.2813,  0.0424,  0.2677, -0.2849,\n",
       "          0.0388,  0.1462],\n",
       "        [ 0.1717, -0.1361,  0.2523, -0.1449,  0.2010, -0.1302, -0.1825, -0.2348,\n",
       "         -0.3094, -0.2001]], requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myLayer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.2584, -0.1258, -0.1378, -0.0786,  0.2008], requires_grad=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myLayer.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4901, 0.0492]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stacking Linear Layers\n",
    "myLayer1 = Linear(10,5)\n",
    "myLayer2 = Linear(5,2)\n",
    "myLayer2(myLayer1(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pytorch non-linear activations\n",
    "sample_data = Variable(torch.Tensor([[1,2,-1,-1]]))\n",
    "myReLU = ReLU()\n",
    "myReLU(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Simpler method\n",
    "import torch.nn.functional as F\n",
    "sample_data = Variable(torch.Tensor([[1,2,-1,-1]]))\n",
    "f = F.relu(sample_data)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural Network\n",
    "class MyFirstNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MyFirstNetWork,self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.layer2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def __forward__(self, input):\n",
    "        out = self.layer1(input)\n",
    "        out = nn.ReLU(out)\n",
    "        out = self.layer2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss\n",
    "loss = nn.MSELoss()\n",
    "input = Variable(torch.randn(3,5), requires_grad=True)\n",
    "target = Variable(torch.randn(3,5))\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(true_label, prediction):\n",
    "    if true_label == 1:\n",
    "        return -log(prediction)\n",
    "    else:\n",
    "        retunr -log(1 - prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input = Variable(torch.randn(3,5),requires_grad=True)\n",
    "target = Variable(torch.LongTensor(3).random_(5))\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport torch.optim as optim\\noptimizer = optim.SGD(model.parameters(), lr=0.01)\\nfor input, target in dataset:\\n    optimizer.zero_grad()\\n    output = model(input)\\n    loss = loss_fn(output, target)\\n    loss.backward()\\n    optimizer.step()\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Optimizer\n",
    "'''\n",
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "for input, target in dataset:\n",
    "    optimizer.zero_grad()\n",
    "    output = model(input)\n",
    "    loss = loss_fn(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
