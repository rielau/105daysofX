{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentClassifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9CbFxFKsSoJ"
      },
      "source": [
        "from torchtext import data,datasets\n",
        "from torchtext.vocab import GloVe,FastText,CharNGram\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torch\n",
        "#from imdb import IMDB\n",
        "import sys"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RdluQ74_sWom",
        "outputId": "5161ea54-6c20-4631-c27d-a71d78b1f824"
      },
      "source": [
        "torch.__version__\n",
        "sys.version"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'3.6.9 (default, Oct  8 2020, 12:12:24) \\n[GCC 8.4.0]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Gl42yf7XstLG",
        "outputId": "cf3ae3b9-1bed-4522-cb2d-a2d4c217bc18"
      },
      "source": [
        "sys.getdefaultencoding()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'utf-8'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcvJDPjYsvSR"
      },
      "source": [
        "is_cuda = False\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    is_cuda=True"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3-XVDNesxiX"
      },
      "source": [
        "TEXT = data.Field(lower=True, batch_first=True,fix_length=40,)\n",
        "LABEL = data.Field(sequential=False,)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Qflywahs0pH",
        "outputId": "a59daff2-1534-4a8d-e90f-a21077132b1a"
      },
      "source": [
        "train, test = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\raclImdb_v1.tar.gz:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:03<00:00, 22.2MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjbkFYGHs6-t",
        "outputId": "8333e070-8cc3-40f0-fb08-0a2b712a7089"
      },
      "source": [
        "type(train)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torchtext.datasets.imdb.IMDB"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7IcJXr2tFOM",
        "outputId": "d1822f82-d023-461d-f01d-9f0f47a30e88"
      },
      "source": [
        "print('train.fields', train.fields)\n",
        "print('len(train)', len(train))\n",
        "print('vars(train[0])', vars(train[0]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train.fields {'text': <torchtext.data.field.Field object at 0x7f33923fd1d0>, 'label': <torchtext.data.field.Field object at 0x7f33923fd240>}\n",
            "len(train) 25000\n",
            "vars(train[0]) {'text': ['this', 'may', 'just', 'be', 'the', 'most', 'nostalgic', 'journey', 'back', 'in', 'time', '&', 'through', 'time', 'to', 'when', \"one's\", 'childhood', 'starts', 'a', 'journey', 'to', 'reminiscences', 'back', '&', 'forth', 'onwards', '&', 'upwards,forwards', '&', 'backwards,up', '&', 'down', '&', 'all', 'around.the', 'boy', 'jimmy,h.r.', 'puffinstuff,dr.blinky,cling', '&', 'clang,ludicrous', 'lion,&', 'even', 'the', 'evil', 'witchie', 'poo', 'too', 'through', '&', 'through.', 'the', 'latter', 'day', 'inspirations', 'of', 'lidsville,\"the', 'brady', 'kids', 'saturday', 'morning', 'preview', 'special\"', 'sigmund', '&', 'the', 'sea', 'monsters,and', 'land', 'of', 'the', 'lost', 'both', 'the', 'new', '&', 'old', 'are', 'what', 'this', 'very', 'show', 'bridged', 'the', 'gap', 'to', 'as', 'well', 'as', 'the', 'donny', '&', 'marie', 'show,the', 'brady', 'bunch', 'variety', 'hour', 'a.k.a.', 'brady', 'bunch', 'hour', '&', 'even', 'the', 'paul', 'lynde', 'halloween', 'special.', 'maybe', 'even', 'other', 'things', 'in', 'between', '&', 'beyond', 'the', 'buck', 'just', 'keeps', 'on', 'moving', 'on', '&', 'on', '&', 'even', 'beyond', 'expectations', '&', 'as', 'well', 'as', 'unexpected', 'bounds.now', 'as', 'we', 'get', 'updated', 'in', 'march', 'of', \"'06\", 'we', 'know', 'that', 'jack', \"wild's\", 'gone', '&', 'so', 'now', 'it', \"make's\", 'it', 'even', 'more', 'symbolic', 'for', 'us', 'to', 'really', 'get', 'nostalgic.including', 'now', 'in', 'august', 'of', \"'06\", 'both', 'when', 'jack', 'wild', 'guest', 'stars', 'as', 'himself', 'on', 'sigmund', 'and', 'the', 'sea', 'monsters', 'as', 'well', 'as', 'when', 'on', 'a', 'latter', 'episode', 'h.r.puffinstuff', 'does', 'too', 'and', 'to', 'recall', 'all', 'of', 'the', 'other', 'nostalgic', 'journeys', 'of', 'all', 'the', 'syd', '&', 'marty', 'kroft', 'characters', 'as', 'well', 'including', 'the', 'h.r.puffinstuff', 'goodtime', 'club;the', 'donny', 'and', 'marie', 'show;the', 'brady', 'bunch', 'variety', 'hour', 'a.k.a.', 'the', 'brady', 'bunch', 'hour;etc.', 'truthfully,stephen', '\"steve\"', 'g.', 'baer', 'a.k.a.', '\"ste\"', 'of', 'framingham,ma.usa.'], 'label': 'pos'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H20AxThZtH0r",
        "outputId": "ee2b6374-65c2-488a-a82e-e7be9aacf105"
      },
      "source": [
        "TEXT.build_vocab(train, vectors=GloVe(name='6B', dim=300),max_size=10000,min_freq=10)\n",
        "LABEL.build_vocab(train,)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [06:28, 2.22MB/s]                           \n",
            "100%|█████████▉| 399335/400000 [00:42<00:00, 9556.78it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBtkJf1NtLiY",
        "outputId": "f2ab4133-d5e3-4ef4-8c52-1fb322411a7a"
      },
      "source": [
        "LABEL.vocab.freqs"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'neg': 12500, 'pos': 12500})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoEpsxw5wS_t"
      },
      "source": [
        "d = vars(TEXT.vocab)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iak4Y8mewYtV",
        "outputId": "cce52599-63c4-41ac-8e1f-c31bfee802f7"
      },
      "source": [
        "d.keys()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['freqs', 'itos', 'stoi', 'vectors'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSVSSUsowaOz",
        "outputId": "ebc4df4f-38bc-41af-a499-a08ed62906a8"
      },
      "source": [
        "TEXT.vocab.vectors"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0466,  0.2132, -0.0074,  ...,  0.0091, -0.2099,  0.0539],\n",
              "        ...,\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.7724, -0.1800,  0.2072,  ...,  0.6736,  0.2263, -0.2919],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCeF-l3YwcoT",
        "outputId": "bd1fe2fd-9d4c-48c1-d286-877a667913c0"
      },
      "source": [
        "len(TEXT.vocab.stoi)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10002"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rwt_K5R8wgc8"
      },
      "source": [
        "train_iter, test_iter = data.BucketIterator.splits((train, test), batch_size=32, device=\"cuda\")\n",
        "\n",
        "train_iter.repeat = False\n",
        "test_iter.repeat = False"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PgDFwPPws8H"
      },
      "source": [
        "class EmbNet(nn.Module):\n",
        "    def __init__(self,emb_size,hidden_size1,hidden_size2=400):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(emb_size,hidden_size1)\n",
        "        self.fc = nn.Linear(hidden_size2,3)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        embeds = self.embedding(x).view(x.size(0),-1)\n",
        "        out = self.fc(embeds)\n",
        "        return F.log_softmax(out,dim=-1)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xnadDxPw0CF"
      },
      "source": [
        "model = EmbNet(len(TEXT.vocab.stoi),10)\n",
        "model = model.cuda()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYOerFPQw18V"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(),lr=0.001)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHTOdg5zzGal"
      },
      "source": [
        "def fit(epoch,model,data_loader,phase='training',volatile=False):\n",
        "    if phase == 'training':\n",
        "        model.train()\n",
        "    if phase == 'validation':\n",
        "        model.eval()\n",
        "        volatile=True\n",
        "    running_loss = 0.0\n",
        "    running_correct = 0\n",
        "    for batch_idx , batch in enumerate(data_loader):\n",
        "        text , target = batch.text , batch.label\n",
        "        text,target = text.cuda(),target.cuda()\n",
        "        \n",
        "        if phase == 'training':\n",
        "            optimizer.zero_grad()\n",
        "        output = model(text)\n",
        "        loss = F.nll_loss(output,target)\n",
        "        \n",
        "        running_loss += F.nll_loss(output,target,reduction=\"sum\").item()\n",
        "        preds = output.data.max(dim=1,keepdim=True)[1]\n",
        "        running_correct += preds.eq(target.data.view_as(preds)).cpu().sum()\n",
        "        if phase == 'training':\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    \n",
        "    loss = running_loss/len(data_loader.dataset)\n",
        "    accuracy = 100. * running_correct/len(data_loader.dataset)\n",
        "    \n",
        "    print(f'{phase} loss is {loss:{5}.{2}} and {phase} accuracy is {running_correct}/{len(data_loader.dataset)}{accuracy:{10}.{4}}')\n",
        "    return loss,accuracy"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FErq_grQzO-5",
        "outputId": "a14abd2d-b95c-41a6-be63-eabdb5e65186"
      },
      "source": [
        "train_losses , train_accuracy = [],[]\n",
        "val_losses , val_accuracy = [],[]\n",
        "\n",
        "for epoch in range(1,10):\n",
        "\n",
        "    epoch_loss, epoch_accuracy = fit(epoch,model,train_iter,phase='training')\n",
        "    val_epoch_loss , val_epoch_accuracy = fit(epoch,model,test_iter,phase='validation')\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracy.append(epoch_accuracy)\n",
        "    val_losses.append(val_epoch_loss)\n",
        "    val_accuracy.append(val_epoch_accuracy)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training loss is  0.43 and training accuracy is 20044/25000     80.18\n",
            "validation loss is  0.62 and validation accuracy is 17374/25000      69.5\n",
            "training loss is   0.4 and training accuracy is 20404/25000     81.62\n",
            "validation loss is  0.64 and validation accuracy is 17390/25000     69.56\n",
            "training loss is  0.38 and training accuracy is 20771/25000     83.08\n",
            "validation loss is  0.65 and validation accuracy is 17450/25000      69.8\n",
            "training loss is  0.36 and training accuracy is 21068/25000     84.27\n",
            "validation loss is  0.67 and validation accuracy is 17492/25000     69.97\n",
            "training loss is  0.33 and training accuracy is 21403/25000     85.61\n",
            "validation loss is  0.69 and validation accuracy is 17444/25000     69.78\n",
            "training loss is  0.31 and training accuracy is 21668/25000     86.67\n",
            "validation loss is  0.71 and validation accuracy is 17462/25000     69.85\n",
            "training loss is  0.29 and training accuracy is 21992/25000     87.97\n",
            "validation loss is  0.74 and validation accuracy is 17418/25000     69.67\n",
            "training loss is  0.27 and training accuracy is 22267/25000     89.07\n",
            "validation loss is  0.78 and validation accuracy is 17301/25000      69.2\n",
            "training loss is  0.25 and training accuracy is 22538/25000     90.15\n",
            "validation loss is  0.81 and validation accuracy is 17351/25000      69.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IrBP21PzRpB"
      },
      "source": [
        "#Using Pretrained Glove Word Embeddings\n",
        "TEXT = data.Field(lower=True, batch_first=True,fix_length=40,)\n",
        "LABEL = data.Field(sequential=False,)\n",
        "\n",
        "train, test = datasets.IMDB.splits(TEXT, LABEL)\n",
        "\n",
        "TEXT.build_vocab(train,test, vectors=GloVe(name='6B', dim=300),max_size=10000,min_freq=10)\n",
        "LABEL.build_vocab(train,)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6pgv53w1kNi"
      },
      "source": [
        "class EmbNet2(nn.Module):\n",
        "    def __init__(self,emb_size,hidden_size1,hidden_size2=400):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(emb_size,hidden_size1)\n",
        "        self.fc1 = nn.Linear(hidden_size2,3)\n",
        "\n",
        "        \n",
        "    def forward(self,x):\n",
        "        embeds = self.embedding(x).view(x.size(0),-1)\n",
        "        out = self.fc1(embeds)\n",
        "        return F.log_softmax(out,dim=-1)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRyrdGwj1v8B"
      },
      "source": [
        "model = EmbNet2(len(TEXT.vocab.stoi),300,12000)\n",
        "model = model.cuda()"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OUJiSvB1yl0"
      },
      "source": [
        "model.embedding.weight.data = TEXT.vocab.vectors.cuda()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdMs9WO_109F"
      },
      "source": [
        "model.embedding.weight.requires_grad = False"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGb7_tyG129f"
      },
      "source": [
        "optimizer = optim.Adam([ param for param in model.parameters() if param.requires_grad == True],lr=0.001)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rwo2jLtP15J1"
      },
      "source": [
        "train_iter, test_iter = data.BucketIterator.splits((train, test), batch_size=64, device=\"cuda\",shuffle=True)\n",
        "train_iter.repeat = False\n",
        "test_iter.repeat = False"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvMrnndB17BE"
      },
      "source": [
        "def fit2(epoch,model,data_loader,phase='training',volatile=False):\n",
        "    if phase == 'training':\n",
        "        model.train()\n",
        "    if phase == 'validation':\n",
        "        model.eval()\n",
        "        volatile=True\n",
        "    running_loss = 0.0\n",
        "    running_correct = 0\n",
        "    for batch_idx , batch in enumerate(data_loader):\n",
        "        text , target = batch.text , batch.label\n",
        "        text,target = text.cuda(),target.cuda()\n",
        "        \n",
        "        if phase == 'training':\n",
        "            optimizer.zero_grad()\n",
        "        output = model(text)\n",
        "        loss = F.nll_loss(output,target)\n",
        "        \n",
        "        running_loss += F.nll_loss(output,target,reduction=\"sum\").item()\n",
        "        preds = output.data.max(dim=1,keepdim=True)[1]\n",
        "        running_correct += preds.eq(target.data.view_as(preds)).cpu().sum()\n",
        "        if phase == 'training':\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    \n",
        "    loss = running_loss/len(data_loader.dataset)\n",
        "    accuracy = 100. * running_correct/len(data_loader.dataset)\n",
        "    \n",
        "    print(f'{phase} loss is {loss:{5}.{2}} and {phase} accuracy is {running_correct}/{len(data_loader.dataset)}{accuracy:{10}.{4}}')\n",
        "    return loss,accuracy"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OyezpKP2Jes",
        "outputId": "6c61bffb-efc4-4a52-d07a-fbb16ba5844d"
      },
      "source": [
        "train_losses2 , train_accuracy2 = [],[]\n",
        "val_losses2 , val_accuracy2 = [],[]\n",
        "\n",
        "for epoch in range(1,10):\n",
        "\n",
        "    epoch_loss, epoch_accuracy = fit2(epoch,model,train_iter,phase='training')\n",
        "    val_epoch_loss , val_epoch_accuracy = fit2(epoch,model,test_iter,phase='validation')\n",
        "    train_losses2.append(epoch_loss)\n",
        "    train_accuracy2.append(epoch_accuracy)\n",
        "    val_losses2.append(val_epoch_loss)\n",
        "    val_accuracy2.append(val_epoch_accuracy)\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training loss is  0.66 and training accuracy is 15657/25000     62.63\n",
            "validation loss is  0.64 and validation accuracy is 16350/25000      65.4\n",
            "training loss is  0.56 and training accuracy is 17785/25000     71.14\n",
            "validation loss is  0.65 and validation accuracy is 16505/25000     66.02\n",
            "training loss is  0.53 and training accuracy is 18339/25000     73.36\n",
            "validation loss is  0.68 and validation accuracy is 16464/25000     65.86\n",
            "training loss is  0.51 and training accuracy is 18778/25000     75.11\n",
            "validation loss is  0.69 and validation accuracy is 16434/25000     65.74\n",
            "training loss is  0.49 and training accuracy is 19065/25000     76.26\n",
            "validation loss is  0.73 and validation accuracy is 16214/25000     64.86\n",
            "training loss is  0.47 and training accuracy is 19237/25000     76.95\n",
            "validation loss is  0.74 and validation accuracy is 16246/25000     64.98\n",
            "training loss is  0.47 and training accuracy is 19376/25000      77.5\n",
            "validation loss is  0.77 and validation accuracy is 16240/25000     64.96\n",
            "training loss is  0.46 and training accuracy is 19479/25000     77.92\n",
            "validation loss is  0.77 and validation accuracy is 16236/25000     64.94\n",
            "training loss is  0.45 and training accuracy is 19633/25000     78.53\n",
            "validation loss is   0.8 and validation accuracy is 16114/25000     64.46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qodFwqBR2WdH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}